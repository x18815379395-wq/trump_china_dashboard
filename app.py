import streamlit as st
import pandas as pd
import requests
import random
from datetime import datetime
from textblob import TextBlob
import plotly.express as px
import time
import os
from typing import List, Dict, Tuple, Optional

# é…ç½®é¡µé¢è®¾ç½®ï¼ˆåº”æ”¾åœ¨æ‰€æœ‰Streamlitå‘½ä»¤ä¹‹å‰ï¼‰
st.set_page_config(
    page_title="ç‰¹æœ—æ™®æƒ…ç»ªç›‘æµ‹ä»ªè¡¨ç›˜",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ======================
# å¸¸é‡å®šä¹‰
# ======================
REFRESH_INTERVAL = 5 * 60  # 5åˆ†é’Ÿåˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰
SENTIMENT_THRESHOLD = 0.1  # æƒ…ç»ªåˆ¤æ–­é˜ˆå€¼
POSTS_CACHE_KEY = "truth_posts"  # ç¼“å­˜é”®å
REFRESH_TIME_KEY = "last_refresh_time"  # ä¸Šæ¬¡åˆ·æ–°æ—¶é—´é”®å
DATA_FILE = "trump_china_sentiment_data.csv"  # æ•°æ®ä¿å­˜æ–‡ä»¶


# ======================
# æ•°æ®è·å–å‡½æ•°
# ======================
def fetch_truth_posts() -> List[Dict]:
    """è·å–ç‰¹æœ—æ™®Truthå¹³å°çš„å¸–å­ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    mock_posts = [
        {"id": 1, "text": "China is manipulating trade again! Not fair!", "timestamp": datetime.now()},
        {"id": 2, "text": "Great meeting with American farmers today! China needs to step up!", "timestamp": datetime.now()},
        {"id": 3, "text": "Chinaâ€™s economy is collapsing, terrible leadership!", "timestamp": datetime.now()},
        {"id": 4, "text": "We will bring manufacturing back from China!", "timestamp": datetime.now()},
        {"id": 5, "text": "Stock market doing great! America first, China second!", "timestamp": datetime.now()},
        {"id": 6, "text": "China has shown some cooperation, thatâ€™s a good sign.", "timestamp": datetime.now()},
        {"id": 7, "text": "Our trade deal with China is working well for both countries.", "timestamp": datetime.now()},
        {"id": 8, "text": "China must respect our intellectual property rights immediately!", "timestamp": datetime.now()},
    ]
    random.shuffle(mock_posts)
    return mock_posts[:random.randint(3, 6)]


# ======================
# æƒ…ç»ªåˆ†æå·¥å…·
# ======================
def analyze_sentiment(text: str) -> Tuple[str, float]:
    """
    åˆ†ææ–‡æœ¬æƒ…ç»ª
    
    Args:
        text: å¾…åˆ†æçš„æ–‡æœ¬
        
    Returns:
        æƒ…ç»ªç±»åˆ«ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰å’Œæƒ…ç»ªå¾—åˆ†
    """
    if not text or not isinstance(text, str):
        return "ä¸­æ€§", 0.0
        
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    
    if polarity > SENTIMENT_THRESHOLD:
        return "æ­£é¢", polarity
    elif polarity < -SENTIMENT_THRESHOLD:
        return "è´Ÿé¢", polarity
    else:
        return "ä¸­æ€§", polarity


# ======================
# æŠ•èµ„å»ºè®®ç”Ÿæˆå™¨
# ======================
def generate_trading_signal(sentiment: str) -> str:
    """æ ¹æ®æƒ…ç»ªç”ŸæˆæŠ•èµ„å»ºè®®"""
    signal_map = {
        "æ­£é¢": "ğŸ“ˆ åšå¤šä¸­å›½ç›¸å…³èµ„äº§",
        "è´Ÿé¢": "ğŸ“‰ åšç©ºä¸­å›½ç›¸å…³èµ„äº§",
        "ä¸­æ€§": "âš–ï¸ è§‚æœ›"
    }
    return signal_map.get(sentiment, "âš–ï¸ è§‚æœ›")


# ======================
# æ•°æ®å¤„ç†å‡½æ•°
# ======================
def process_posts(posts: List[Dict]) -> pd.DataFrame:
    """å¤„ç†åŸå§‹å¸–å­æ•°æ®ï¼Œç”Ÿæˆå¸¦æƒ…ç»ªåˆ†æå’ŒæŠ•èµ„å»ºè®®çš„DataFrame"""
    processed_data = []
    
    for post in posts:
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        if not all(key in post for key in ["text", "timestamp", "id"]):
            continue
            
        # è¿‡æ»¤åŒ…å«Chinaçš„å¸–å­
        if "china" not in post["text"].lower():
            continue
            
        # åˆ†ææƒ…ç»ªå¹¶ç”Ÿæˆå»ºè®®
        sentiment, score = analyze_sentiment(post["text"])
        signal = generate_trading_signal(sentiment)
        
        processed_data.append({
            "å¸–å­ID": post["id"],
            "æ—¶é—´": post["timestamp"].strftime("%Y-%m-%d %H:%M:%S"),
            "åŸå§‹æ—¶é—´": post["timestamp"],  # ä¿å­˜åŸå§‹æ—¶é—´ç”¨äºæ’åº
            "å†…å®¹": post["text"],
            "æƒ…ç»ª": sentiment,
            "æƒ…ç»ªå¾—åˆ†": round(score, 3),
            "æŠ•èµ„å»ºè®®": signal,
            "æŠ“å–æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })
    
    return pd.DataFrame(processed_data)


# ======================
# æ•°æ®ä¿å­˜å‡½æ•°ï¼ˆä¿®å¤æ—¶é—´ç±»å‹é—®é¢˜ï¼‰
# ======================
def save_data_to_csv(df: pd.DataFrame) -> None:
    """å°†å¤„ç†åçš„æ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶ï¼Œé¿å…é‡å¤æ•°æ®"""
    if df.empty:
        return
        
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(DATA_FILE):
        # è¯»å–å·²æœ‰æ•°æ®
        existing_df = pd.read_csv(DATA_FILE)
        # å…³é”®ä¿®å¤ï¼šå°†ç°æœ‰æ•°æ®çš„"åŸå§‹æ—¶é—´"è½¬æ¢ä¸ºdatetimeç±»å‹
        existing_df["åŸå§‹æ—¶é—´"] = pd.to_datetime(existing_df["åŸå§‹æ—¶é—´"])
        # åˆå¹¶æ•°æ®å¹¶å»é‡ï¼ˆåŸºäºå¸–å­IDï¼‰
        combined_df = pd.concat([existing_df, df]).drop_duplicates(subset=["å¸–å­ID"], keep="last")
    else:
        combined_df = df
    
    # æŒ‰æ—¶é—´æ’åºå¹¶ä¿å­˜
    combined_df = combined_df.sort_values(by="åŸå§‹æ—¶é—´", ascending=False)
    combined_df.to_csv(DATA_FILE, index=False)


# ======================
# å¯è§†åŒ–ç»„ä»¶
# ======================
def plot_sentiment_distribution(df: pd.DataFrame) -> None:
    """ç»˜åˆ¶æƒ…ç»ªåˆ†å¸ƒæŸ±çŠ¶å›¾"""
    sentiment_counts = df["æƒ…ç»ª"].value_counts().reset_index()
    sentiment_counts.columns = ["æƒ…ç»ªç±»å‹", "æ•°é‡"]
    
    fig = px.bar(
        sentiment_counts,
        x="æƒ…ç»ªç±»å‹",
        y="æ•°é‡",
        color="æƒ…ç»ªç±»å‹",
        text="æ•°é‡",
        title="ç‰¹æœ—æ™®å¯¹ä¸­å›½è¨€è®ºçš„æƒ…ç»ªåˆ†å¸ƒ",
        color_discrete_map={
            "æ­£é¢": "green",
            "è´Ÿé¢": "red",
            "ä¸­æ€§": "gray"
        }
    )
    st.plotly_chart(fig, use_container_width=True)


# ======================
# ç¼“å­˜ç®¡ç†
# ======================
def refresh_posts() -> List[Dict]:
    """åˆ·æ–°å¸–å­æ•°æ®å¹¶æ›´æ–°ç¼“å­˜"""
    new_posts = fetch_truth_posts()
    st.session_state[POSTS_CACHE_KEY] = new_posts
    st.session_state[REFRESH_TIME_KEY] = time.time()
    return new_posts


def get_cached_posts(force_refresh: bool = False) -> List[Dict]:
    """è·å–ç¼“å­˜çš„å¸–å­æ•°æ®ï¼Œå¯å¼ºåˆ¶åˆ·æ–°"""
    if force_refresh:
        return refresh_posts()
        
    current_time = time.time()
    last_refresh = st.session_state.get(REFRESH_TIME_KEY, 0)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ•°æ®
    if current_time - last_refresh > REFRESH_INTERVAL:
        return refresh_posts()
    
    return st.session_state.get(POSTS_CACHE_KEY, fetch_truth_posts())


# ======================
# ä¸»é¡µé¢æ¸²æŸ“
# ======================
def main():
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ‡ºğŸ‡¸ ç‰¹æœ—æ™® Truth å¹³å° Â· ä¸­å›½ç›¸å…³è¨€è®ºç›‘æµ‹")
    st.caption("è‡ªåŠ¨æŠ“å–ã€æƒ…ç»ªåˆ†æã€æŠ•èµ„å»ºè®®ä¸æ•°æ®è¿½è¸ª")
    st.divider()
    
    # åˆ·æ–°æ§åˆ¶
    col1, col2 = st.columns([1, 5])
    with col1:
        if st.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°æ•°æ®", use_container_width=True):
            with st.spinner("æ­£åœ¨åˆ·æ–°æœ€æ–°æ•°æ®..."):
                get_cached_posts(force_refresh=True)
                st.success("æ•°æ®å·²æ›´æ–°!")
                # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæœ€æ–°æ•°æ®
                st.experimental_rerun()
    
    with col2:
        last_refresh_time = datetime.fromtimestamp(
            st.session_state.get(REFRESH_TIME_KEY, time.time())
        ).strftime("%Y-%m-%d %H:%M:%S")
        st.info(f"â± æœ€æ–°æ›´æ–°æ—¶é—´: {last_refresh_time}", icon="â„¹ï¸")
    
    # è·å–å¹¶å¤„ç†æ•°æ®
    posts = get_cached_posts()
    df = process_posts(posts)
    
    # ä¿å­˜æ•°æ®åˆ°CSV
    if not df.empty:
        save_data_to_csv(df)
        # æ˜¾ç¤ºæ•°æ®æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(DATA_FILE) if os.path.exists(DATA_FILE) else 0
        st.caption(f"ğŸ’¾ æ•°æ®å·²è‡ªåŠ¨ä¿å­˜åˆ° {DATA_FILE}ï¼ˆæ–‡ä»¶å¤§å°: {file_size/1024:.1f} KBï¼‰")
    
    # æ˜¾ç¤ºç»“æœ
    if df.empty:
        st.info("æš‚æ— æ¶‰åŠ China çš„å¸–å­ï¼Œè¯·ç¨åå†è¯•ã€‚")
    else:
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        st.subheader("æœ€æ–°è¨€è®ºåˆ†æ")
        # æ˜¾ç¤ºæ—¶æ’é™¤åŸå§‹æ—¶é—´åˆ—
        display_df = df.drop(columns=["åŸå§‹æ—¶é—´"])
        st.dataframe(display_df, use_container_width=True)
        
        # æ˜¾ç¤ºæƒ…ç»ªåˆ†å¸ƒå›¾è¡¨
        st.subheader("ğŸ“‰ æƒ…ç»ªåˆ†å¸ƒ")
        plot_sentiment_distribution(df)
        
        # æŠ•èµ„å»ºè®®æ€»ç»“
        st.subheader("ğŸ’¡ æŠ•èµ„å»ºè®®æ€»ç»“")
        sentiment_score = df["æƒ…ç»ªå¾—åˆ†"].mean()
        
        if sentiment_score > SENTIMENT_THRESHOLD:
            st.success(f"æ•´ä½“æƒ…ç»ªåæ­£é¢ï¼ˆå¹³å‡å¾—åˆ†: {sentiment_score:.3f}ï¼‰ï¼šå¯è€ƒè™‘é€‚åº¦åšå¤šä¸­å›½å¸‚åœºã€‚")
        elif sentiment_score < -SENTIMENT_THRESHOLD:
            st.error(f"æ•´ä½“æƒ…ç»ªåè´Ÿé¢ï¼ˆå¹³å‡å¾—åˆ†: {sentiment_score:.3f}ï¼‰ï¼šå¯è€ƒè™‘é€‚åº¦åšç©ºä¸­å›½å¸‚åœºã€‚")
        else:
            st.warning(f"æ•´ä½“æƒ…ç»ªä¸­æ€§ï¼ˆå¹³å‡å¾—åˆ†: {sentiment_score:.3f}ï¼‰ï¼šå»ºè®®è§‚æœ›ï¼Œç­‰å¾…æ›´å¤šä¿¡å·ã€‚")
    
    # æ˜¾ç¤ºåˆ·æ–°ä¿¡æ¯
    st.caption(f"æ•°æ®å°†æ¯éš” {REFRESH_INTERVAL//60} åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°")


if __name__ == "__main__":
    main()
    
